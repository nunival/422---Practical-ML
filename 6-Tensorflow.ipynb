{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcE1GTVmI82x"
   },
   "source": [
    "# Week 6 - Neural Networks\n",
    "<i>MSDS422</i>\n",
    "\n",
    "---\n",
    "\n",
    "You will continue work on the Digit Recognition problem in Kaggle.com this week.   As in Assignment 5, we will assess classification performance accuracy and processing time. Python TensorFlow / Keras should be used for Assignment 6. (If you experience difficulty installing TensorFlow, Python scikit-learn may be used as an alternative for Assignment 6.)\n",
    "The Benchmark Experiment\n",
    "\n",
    "Tested neural network structures should be explored within a benchmark experiment, a factorial design with at least two levels on each of two experimental factors (at least a 2x2 completely crossed design).  You will build your models on train.csv and submit your forecasts for test.csv to Kaggle.com, providing your name and user ID for each experimental trial..\n",
    "\n",
    "An example experiment could include two values for the number of nodes per inner layer and two values for the number of inner layers. Various machine learning hyperparameter settings may be used.\n",
    "\n",
    "In summary, this assignment asks you to fit a number of neural networks, comparing processing time and performance across experimental treatments. Processing time will be recorded for the fitting on the train.csv.  Kaggle.com accuracy scores will be reported for all benchmarks.  \n",
    "\n",
    "## Management Question\n",
    "\n",
    "Suppose you are a financial institution evaluating machine learning technologies for optical character recognition. Initial testing is on the MNIST digits. What can you conclude from your benchmark study? Which neural network typology and hyperparameter settings would you recommend as being the most trustworthy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvJMbB7FLuzP"
   },
   "source": [
    "## Results:\n",
    "\n",
    "I chose to do my benchmark evaluation on two prameters; number of hidden layers and nodes per layer. For all 4 models I used 30 epochs. I followed the example provided in Geron and used a Sequential TensorFlow model. To make life easier I actually created a function that included all of the steps; building the model, timing it, producing a graph of the results, predicting on the test set, and packing it up for submission to Kaggle. The table below show the results of all 4 tests:\n",
    "\n",
    "|Model #| Number of Hidden Layers | Nodes per Layer | Processing Time | Training Accuracy | Test Accuracy| Kaggle Score |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | 2 | 20 | 00:51.9 | 96.26% | 94.99% | 94.742% |\n",
    "| 2 | 2 | 100 | 01:08.4 | 98.51% | 96.67% | 96.514% |\n",
    "| 3 | 4 | 20 | 00:53.1 | 97.01% | 95.32% | 94.585% |\n",
    "| 4 | 4 | 100 | 01:09.6 | 99.61% | 96.75% | 96.600% |\n",
    "\n",
    "As you can see the last model performed the best. Clearly though we started to overfit the model towards the end because we see that the training accuracy nears 100% however the test accuracy stagnates. The charts and model output allow us to see that. It was also interesting to see that increasing the number of hidden layers had very minimal effects on the time to run the model however the number of nodes dramatically increases it. While it costed us time, increasing the nodes had the best effect on increasing the accuracy. \n",
    "\n",
    "**Management Answer:** \n",
    "Based on this benchmark study I found the number of nodes per hidden layer to have the best effect on increasing accuracy as compared to number of hidden layers. This study is limited because there are many other things that could be tested or changed that will affect accuracy. A more thorough study should be conducted to include more parameters/models.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix and Code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQQSx55L-xvw"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "sNoRflDs6BHe",
    "outputId": "0892a888-853d-4007-bc98-eeb28002808a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#Data Prep\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "import datetime\n",
    "#Modeling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#Validation\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "qHbMLSFh6Lzk",
    "outputId": "b0a9bb21-cfb8-4eb9-bd94-bbc57f301279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc4'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comfirming Tensorflow works, I couldn't get this to run on my computer. \n",
    "# It works here in google colab, hooray!\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWELVOzgCStq"
   },
   "outputs": [],
   "source": [
    "# Ensuring the models are repeatable\n",
    "tf.random.set_seed = '1776'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4H87d4w-8gU"
   },
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "yTWGcD9bCMo0",
    "outputId": "0f12f9e5-1aca-4450-a04b-7ee2609722d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8202006b-5d77-46db-b4e3-a0a5dbb78e40\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8202006b-5d77-46db-b4e3-a0a5dbb78e40\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"gallagh4\",\"key\":\"c768cc31a82d10dd6a7d53a0a741bc3c\"}'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# installing the kaggle package\n",
    "!pip install -U -q kaggle\n",
    "\n",
    "# Making a new directory for kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# Uploading my kaggle.json api key\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMDZab22DwiG"
   },
   "outputs": [],
   "source": [
    "# copying my api key to my new kaggle folder\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "# Hiding my API key\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XOtMhf6c6OEB",
    "outputId": "9fa27a70-5cda-4029-b158-d1c267bc414c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading sample_submission.csv to /content\n",
      "\r",
      "  0% 0.00/235k [00:00<?, ?B/s]\n",
      "100% 235k/235k [00:00<00:00, 35.1MB/s]\n",
      "Downloading test.csv.zip to /content\n",
      "  0% 0.00/6.09M [00:00<?, ?B/s]\n",
      "100% 6.09M/6.09M [00:00<00:00, 99.2MB/s]\n",
      "Downloading train.csv.zip to /content\n",
      " 76% 7.00M/9.16M [00:00<00:00, 71.6MB/s]\n",
      "100% 9.16M/9.16M [00:00<00:00, 84.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Grabbing dataset from kaggle\n",
    "!kaggle competitions download -c digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nrus1-bi_Iqa"
   },
   "outputs": [],
   "source": [
    "# reading in datasets\n",
    "df_train = pd.read_csv('/content/train.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
    "df_val = pd.read_csv('/content/test.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "qXnlg-ZnBKJb",
    "outputId": "e9862570-ffd0-4e2c-92fc-4825fba16773"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0      1       0       0       0  ...         0         0         0         0\n",
       "1      0       0       0       0  ...         0         0         0         0\n",
       "2      1       0       0       0  ...         0         0         0         0\n",
       "3      4       0       0       0  ...         0         0         0         0\n",
       "4      0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBXGwGJHFv7N"
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIYtZl9TFQlD"
   },
   "outputs": [],
   "source": [
    "# Splitting the training into training and test sets\n",
    "# Also scaling the data by dividing by 255\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['label'], axis= 1)/255,\n",
    "                                                    df_train.loc[:,'label'], \n",
    "                                                    train_size = 0.8,\n",
    "                                                    random_state = 1776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40l-n_zEC8Js"
   },
   "outputs": [],
   "source": [
    "# Scaling the validation data\n",
    "df_val = df_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grviAGw1Nt0x"
   },
   "outputs": [],
   "source": [
    "# Defining function for running the tensorflow model\n",
    "\n",
    "def tfmodel(hidden_layers, nodes, model_num):\n",
    "\n",
    "  # Starting a timer\n",
    "  start = datetime.datetime.now()\n",
    "\n",
    "  # Building Model\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Flatten())\n",
    "  for num in range(0,hidden_layers):\n",
    "    model.add(keras.layers.Dense(nodes, activation = 'relu'))\n",
    "  model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "  #Compiling the model\n",
    "  model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                optimizer = 'sgd',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "  # Training and evaluating the model\n",
    "  history = model.fit(X_train,y_train, epochs = 30, validation_data = (X_test, y_test))\n",
    "\n",
    "  # End time\n",
    "  end = datetime.datetime.now()\n",
    "  print(\"Elapsed Time: \",end-start)\n",
    "\n",
    "  # Making a graph to view the results over the 30 epoches\n",
    "  pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "  plt.grid(True)\n",
    "  plt.gca().set_ylim(0,1)\n",
    "  plt.show()\n",
    "\n",
    "  ################## Prepping Submission for Kaggle ###############################################\n",
    "\n",
    "  # Transforming and predicting on Kaggle's test set\n",
    "  final_predictions = model.predict_classes(df_val)\n",
    "\n",
    "  # Packaging submission up\n",
    "  ImageId = df_val.index+1\n",
    "  my_solution = pd.DataFrame(final_predictions, ImageId, columns = ['label'])\n",
    "  my_solution.to_csv(\"submission{}.csv\".format(model_num), index_label = [\"ImageId\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0Hiv-wEFLf1"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyeczZIxPpVq"
   },
   "source": [
    "Model 1: 2 hidden layers, 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "y2XG7BIbOZtx",
    "outputId": "2289f809-a9bc-40fb-e1da-188eb234de1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 1.1736 - accuracy: 0.6476 - val_loss: 0.5675 - val_accuracy: 0.8352\n",
      "Epoch 2/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.8683 - val_loss: 0.3967 - val_accuracy: 0.8867\n",
      "Epoch 3/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3586 - accuracy: 0.8956 - val_loss: 0.3383 - val_accuracy: 0.9029\n",
      "Epoch 4/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3154 - accuracy: 0.9086 - val_loss: 0.3081 - val_accuracy: 0.9105\n",
      "Epoch 5/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2884 - accuracy: 0.9162 - val_loss: 0.2902 - val_accuracy: 0.9169\n",
      "Epoch 6/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2674 - accuracy: 0.9222 - val_loss: 0.2727 - val_accuracy: 0.9202\n",
      "Epoch 7/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2504 - accuracy: 0.9266 - val_loss: 0.2672 - val_accuracy: 0.9224\n",
      "Epoch 8/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.9310 - val_loss: 0.2537 - val_accuracy: 0.9258\n",
      "Epoch 9/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2251 - accuracy: 0.9345 - val_loss: 0.2395 - val_accuracy: 0.9318\n",
      "Epoch 10/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2147 - accuracy: 0.9370 - val_loss: 0.2330 - val_accuracy: 0.9338\n",
      "Epoch 11/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2064 - accuracy: 0.9400 - val_loss: 0.2257 - val_accuracy: 0.9361\n",
      "Epoch 12/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1986 - accuracy: 0.9413 - val_loss: 0.2168 - val_accuracy: 0.9389\n",
      "Epoch 13/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1915 - accuracy: 0.9433 - val_loss: 0.2117 - val_accuracy: 0.9390\n",
      "Epoch 14/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1852 - accuracy: 0.9451 - val_loss: 0.2098 - val_accuracy: 0.9369\n",
      "Epoch 15/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1802 - accuracy: 0.9475 - val_loss: 0.2060 - val_accuracy: 0.9388\n",
      "Epoch 16/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1749 - accuracy: 0.9483 - val_loss: 0.2024 - val_accuracy: 0.9404\n",
      "Epoch 17/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1701 - accuracy: 0.9502 - val_loss: 0.2045 - val_accuracy: 0.9419\n",
      "Epoch 18/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1658 - accuracy: 0.9512 - val_loss: 0.2017 - val_accuracy: 0.9381\n",
      "Epoch 19/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1613 - accuracy: 0.9525 - val_loss: 0.1996 - val_accuracy: 0.9393\n",
      "Epoch 20/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1579 - accuracy: 0.9544 - val_loss: 0.1923 - val_accuracy: 0.9429\n",
      "Epoch 21/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1539 - accuracy: 0.9545 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
      "Epoch 22/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.9567 - val_loss: 0.1858 - val_accuracy: 0.9471\n",
      "Epoch 23/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1478 - accuracy: 0.9569 - val_loss: 0.1868 - val_accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1442 - accuracy: 0.9576 - val_loss: 0.1922 - val_accuracy: 0.9443\n",
      "Epoch 25/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1412 - accuracy: 0.9582 - val_loss: 0.1779 - val_accuracy: 0.9483\n",
      "Epoch 26/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1384 - accuracy: 0.9593 - val_loss: 0.1784 - val_accuracy: 0.9476\n",
      "Epoch 27/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1355 - accuracy: 0.9603 - val_loss: 0.1826 - val_accuracy: 0.9445\n",
      "Epoch 28/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1323 - accuracy: 0.9609 - val_loss: 0.1795 - val_accuracy: 0.9477\n",
      "Epoch 29/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1295 - accuracy: 0.9627 - val_loss: 0.1731 - val_accuracy: 0.9487\n",
      "Epoch 30/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1274 - accuracy: 0.9626 - val_loss: 0.1741 - val_accuracy: 0.9499\n",
      "Elapsed Time:  0:00:51.945139\n"
     ]
    }
   ],
   "source": [
    "tfmodel(2,20,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk4SbUNJPOtm"
   },
   "source": [
    "Tensorflow Model 2: 2 hidden layers, 100 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Hg01_wMdPUfH",
    "outputId": "63dde885-c152-40ed-84fb-c13562d6dd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layer flatten_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.8218 - accuracy: 0.7886 - val_loss: 0.4140 - val_accuracy: 0.8840\n",
      "Epoch 2/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3509 - accuracy: 0.8988 - val_loss: 0.3224 - val_accuracy: 0.9067\n",
      "Epoch 3/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2924 - accuracy: 0.9150 - val_loss: 0.2839 - val_accuracy: 0.9194\n",
      "Epoch 4/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.9246 - val_loss: 0.2583 - val_accuracy: 0.9260\n",
      "Epoch 5/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2347 - accuracy: 0.9314 - val_loss: 0.2395 - val_accuracy: 0.9319\n",
      "Epoch 6/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9373 - val_loss: 0.2214 - val_accuracy: 0.9370\n",
      "Epoch 7/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1970 - accuracy: 0.9429 - val_loss: 0.2054 - val_accuracy: 0.9412\n",
      "Epoch 8/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1817 - accuracy: 0.9472 - val_loss: 0.1925 - val_accuracy: 0.9437\n",
      "Epoch 9/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1690 - accuracy: 0.9516 - val_loss: 0.1845 - val_accuracy: 0.9473\n",
      "Epoch 10/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1573 - accuracy: 0.9548 - val_loss: 0.1802 - val_accuracy: 0.9485\n",
      "Epoch 11/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1473 - accuracy: 0.9581 - val_loss: 0.1671 - val_accuracy: 0.9525\n",
      "Epoch 12/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1383 - accuracy: 0.9609 - val_loss: 0.1632 - val_accuracy: 0.9527\n",
      "Epoch 13/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1303 - accuracy: 0.9633 - val_loss: 0.1532 - val_accuracy: 0.9544\n",
      "Epoch 14/30\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1236 - accuracy: 0.9652 - val_loss: 0.1498 - val_accuracy: 0.9539\n",
      "Epoch 15/30\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1168 - accuracy: 0.9666 - val_loss: 0.1438 - val_accuracy: 0.9563\n",
      "Epoch 16/30\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.1385 - val_accuracy: 0.9588\n",
      "Epoch 17/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1053 - accuracy: 0.9706 - val_loss: 0.1338 - val_accuracy: 0.9601\n",
      "Epoch 18/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1002 - accuracy: 0.9726 - val_loss: 0.1319 - val_accuracy: 0.9605\n",
      "Epoch 19/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.9736 - val_loss: 0.1275 - val_accuracy: 0.9619\n",
      "Epoch 20/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.9741 - val_loss: 0.1273 - val_accuracy: 0.9620\n",
      "Epoch 21/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.9757 - val_loss: 0.1243 - val_accuracy: 0.9620\n",
      "Epoch 22/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.9771 - val_loss: 0.1221 - val_accuracy: 0.9632\n",
      "Epoch 23/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.9778 - val_loss: 0.1201 - val_accuracy: 0.9650\n",
      "Epoch 24/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.9784 - val_loss: 0.1196 - val_accuracy: 0.9633\n",
      "Epoch 25/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.9801 - val_loss: 0.1167 - val_accuracy: 0.9651\n",
      "Epoch 26/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0702 - accuracy: 0.9808 - val_loss: 0.1143 - val_accuracy: 0.9646\n",
      "Epoch 27/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0671 - accuracy: 0.9809 - val_loss: 0.1157 - val_accuracy: 0.9669\n",
      "Epoch 28/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0642 - accuracy: 0.9827 - val_loss: 0.1111 - val_accuracy: 0.9681\n",
      "Epoch 29/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0616 - accuracy: 0.9833 - val_loss: 0.1098 - val_accuracy: 0.9667\n",
      "Epoch 30/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0591 - accuracy: 0.9836 - val_loss: 0.1087 - val_accuracy: 0.9674\n",
      "Elapsed Time:  0:01:13.228565\n",
      "WARNING:tensorflow:From <ipython-input-24-2d51f146d700>:29: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "tfmodel(2,100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJxPwYMKQIca"
   },
   "source": [
    "Tensorflow Model 3: 4 hidden layers, 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VTVrDhl9QGDH",
    "outputId": "2c98f7e1-f975-4c40-fc66-b33d69ec8181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layer flatten_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 1.6780 - accuracy: 0.4231 - val_loss: 0.8082 - val_accuracy: 0.7375\n",
      "Epoch 2/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5738 - accuracy: 0.8223 - val_loss: 0.4327 - val_accuracy: 0.8714\n",
      "Epoch 3/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3787 - accuracy: 0.8836 - val_loss: 0.3771 - val_accuracy: 0.8848\n",
      "Epoch 4/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3057 - accuracy: 0.9094 - val_loss: 0.2948 - val_accuracy: 0.9107\n",
      "Epoch 5/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2619 - accuracy: 0.9229 - val_loss: 0.2695 - val_accuracy: 0.9194\n",
      "Epoch 6/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2328 - accuracy: 0.9311 - val_loss: 0.2306 - val_accuracy: 0.9338\n",
      "Epoch 7/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2133 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9313\n",
      "Epoch 8/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1956 - accuracy: 0.9435 - val_loss: 0.2128 - val_accuracy: 0.9388\n",
      "Epoch 9/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1856 - accuracy: 0.9454 - val_loss: 0.2198 - val_accuracy: 0.9345\n",
      "Epoch 10/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1751 - accuracy: 0.9481 - val_loss: 0.1989 - val_accuracy: 0.9415\n",
      "Epoch 11/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1667 - accuracy: 0.9499 - val_loss: 0.1884 - val_accuracy: 0.9432\n",
      "Epoch 12/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1587 - accuracy: 0.9529 - val_loss: 0.1891 - val_accuracy: 0.9454\n",
      "Epoch 13/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1523 - accuracy: 0.9545 - val_loss: 0.2391 - val_accuracy: 0.9280\n",
      "Epoch 14/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1465 - accuracy: 0.9560 - val_loss: 0.1926 - val_accuracy: 0.9426\n",
      "Epoch 15/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1394 - accuracy: 0.9582 - val_loss: 0.1804 - val_accuracy: 0.9470\n",
      "Epoch 16/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1367 - accuracy: 0.9590 - val_loss: 0.1934 - val_accuracy: 0.9461\n",
      "Epoch 17/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1318 - accuracy: 0.9608 - val_loss: 0.1778 - val_accuracy: 0.9458\n",
      "Epoch 18/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1279 - accuracy: 0.9621 - val_loss: 0.1710 - val_accuracy: 0.9482\n",
      "Epoch 19/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1221 - accuracy: 0.9630 - val_loss: 0.1706 - val_accuracy: 0.9495\n",
      "Epoch 20/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1198 - accuracy: 0.9640 - val_loss: 0.1716 - val_accuracy: 0.9496\n",
      "Epoch 21/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1157 - accuracy: 0.9659 - val_loss: 0.1743 - val_accuracy: 0.9487\n",
      "Epoch 22/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.1784 - val_accuracy: 0.9485\n",
      "Epoch 23/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1092 - accuracy: 0.9670 - val_loss: 0.1754 - val_accuracy: 0.9490\n",
      "Epoch 24/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.9670 - val_loss: 0.1726 - val_accuracy: 0.9498\n",
      "Epoch 25/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1029 - accuracy: 0.9686 - val_loss: 0.1641 - val_accuracy: 0.9530\n",
      "Epoch 26/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.9696 - val_loss: 0.1655 - val_accuracy: 0.9523\n",
      "Epoch 27/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0980 - accuracy: 0.9700 - val_loss: 0.1700 - val_accuracy: 0.9520\n",
      "Epoch 28/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.9716 - val_loss: 0.1725 - val_accuracy: 0.9523\n",
      "Epoch 29/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.9708 - val_loss: 0.1660 - val_accuracy: 0.9540\n",
      "Epoch 30/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.9717 - val_loss: 0.1742 - val_accuracy: 0.9502\n",
      "Elapsed Time:  0:00:58.032635\n"
     ]
    }
   ],
   "source": [
    "tfmodel(4,20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JF_0mO6SQf9q",
    "outputId": "c16e0189-3007-43e7-be80-544c56552cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layer flatten_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 1.0469 - accuracy: 0.6839 - val_loss: 0.4432 - val_accuracy: 0.8701\n",
      "Epoch 2/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8955 - val_loss: 0.3207 - val_accuracy: 0.9080\n",
      "Epoch 3/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.2765 - accuracy: 0.9180 - val_loss: 0.2615 - val_accuracy: 0.9230\n",
      "Epoch 4/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.2298 - accuracy: 0.9321 - val_loss: 0.2662 - val_accuracy: 0.9207\n",
      "Epoch 5/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1980 - accuracy: 0.9408 - val_loss: 0.1998 - val_accuracy: 0.9414\n",
      "Epoch 6/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1718 - accuracy: 0.9488 - val_loss: 0.2087 - val_accuracy: 0.9376\n",
      "Epoch 7/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.1527 - accuracy: 0.9546 - val_loss: 0.1623 - val_accuracy: 0.9535\n",
      "Epoch 8/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1374 - accuracy: 0.9585 - val_loss: 0.1524 - val_accuracy: 0.9555\n",
      "Epoch 9/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1221 - accuracy: 0.9632 - val_loss: 0.1748 - val_accuracy: 0.9462\n",
      "Epoch 10/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.1108 - accuracy: 0.9674 - val_loss: 0.1477 - val_accuracy: 0.9549\n",
      "Epoch 11/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1002 - accuracy: 0.9708 - val_loss: 0.1354 - val_accuracy: 0.9581\n",
      "Epoch 12/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.9724 - val_loss: 0.1361 - val_accuracy: 0.9582\n",
      "Epoch 13/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.9751 - val_loss: 0.1258 - val_accuracy: 0.9621\n",
      "Epoch 14/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.9772 - val_loss: 0.1340 - val_accuracy: 0.9583\n",
      "Epoch 15/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.9793 - val_loss: 0.1180 - val_accuracy: 0.9649\n",
      "Epoch 16/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0649 - accuracy: 0.9812 - val_loss: 0.1163 - val_accuracy: 0.9661\n",
      "Epoch 17/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.1106 - val_accuracy: 0.9679\n",
      "Epoch 18/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.1089 - val_accuracy: 0.9686\n",
      "Epoch 19/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 0.1169 - val_accuracy: 0.9661\n",
      "Epoch 20/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0461 - accuracy: 0.9873 - val_loss: 0.1102 - val_accuracy: 0.9689\n",
      "Epoch 21/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0432 - accuracy: 0.9876 - val_loss: 0.1132 - val_accuracy: 0.9673\n",
      "Epoch 22/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0387 - accuracy: 0.9897 - val_loss: 0.1089 - val_accuracy: 0.9692\n",
      "Epoch 23/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 0.1125 - val_accuracy: 0.9665\n",
      "Epoch 24/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0329 - accuracy: 0.9917 - val_loss: 0.1123 - val_accuracy: 0.9673\n",
      "Epoch 25/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 0.1125 - val_accuracy: 0.9690\n",
      "Epoch 26/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0278 - accuracy: 0.9930 - val_loss: 0.1070 - val_accuracy: 0.9696\n",
      "Epoch 27/30\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 0.1066 - val_accuracy: 0.9704\n",
      "Epoch 28/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.1355 - val_accuracy: 0.9637\n",
      "Epoch 29/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0204 - accuracy: 0.9955 - val_loss: 0.1136 - val_accuracy: 0.9689\n",
      "Epoch 30/30\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.1117 - val_accuracy: 0.9696\n",
      "Elapsed Time:  0:01:15.843253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfmodel(4,100,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-Pz9iFCaM_"
   },
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "PiVibd55FWhg",
    "outputId": "df74b2ce-cff7-43e4-ea5f-15b44a667794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "100% 208k/208k [00:00<00:00, 513kB/s]\n",
      "Successfully submitted to Digit Recognizer"
     ]
    }
   ],
   "source": [
    "# Submitting to kaggle\n",
    "!kaggle competitions submit -c digit-recognizer -f submission4.csv -m \"Week 6: Sub 4 - TF(4 layers, 100 nodes)\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6 - Tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
